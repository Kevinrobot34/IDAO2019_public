{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tables\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import repeat\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas(desc=\"\")\n",
    "import sys, gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import model_tuner\n",
    "import scoring, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCHEDHIT_MISSING_COL = ['MatchedHit_X[2]', 'MatchedHit_X[3]', 'MatchedHit_Y[2]', 'MatchedHit_Y[3]', \n",
    "                           'MatchedHit_Z[2]', 'MatchedHit_Z[3]', 'MatchedHit_DX[2]', 'MatchedHit_DX[3]', \n",
    "                           'MatchedHit_DY[2]', 'MatchedHit_DY[3]', 'MatchedHit_DZ[2]', 'MatchedHit_DZ[3]']\n",
    "CLOSESTHIT_MISSING_COL = ['closest_x_per_station[2]', 'closest_x_per_station[3]', \n",
    "                    'closest_y_per_station[2]', 'closest_y_per_station[3]',\n",
    "                    'closest_T_per_station[2]', 'closest_T_per_station[3]',\n",
    "                    'closest_z_per_station[2]', 'closest_z_per_station[3]',\n",
    "                    'closest_dx_per_station[2]', 'closest_dx_per_station[3]',\n",
    "                    'closest_dy_per_station[2]', 'closest_dy_per_station[3]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_imputation(dataDF, essential=False, ratio_f=True, substitution_f=True, mean_f=True, angle_f=True, average_xy_f=True):\n",
    "    imputation_dict = {\n",
    "        'MatchedHit_X[2]':'Lextra_X[2]', \n",
    "        'MatchedHit_X[3]':'Lextra_X[3]', \n",
    "        'MatchedHit_Y[2]':'Lextra_Y[2]',\n",
    "        'MatchedHit_Y[3]':'Lextra_Y[3]',\n",
    "        'closest_T_per_station[2]':'MatchedHit_T[2]',\n",
    "        'closest_T_per_station[3]':'MatchedHit_T[3]'\n",
    "    }\n",
    "    if ratio_f == True:\n",
    "        for station in tqdm([2,3], desc='ratio imputation'): # Assume the ratio of DX(n+1)/DX(n) is the same\n",
    "            MatchedHit_R = {}\n",
    "            closesthit_R = {}\n",
    "            for axis in ['X', 'Y', 'Z']:\n",
    "                MatchedHit_R[axis] = \\\n",
    "                dataDF['MatchedHit_D{}[{}]'.format(axis,station)].dropna().median() / dataDF['MatchedHit_D{}[{}]'.format(axis,station-1)].dropna().median()\n",
    "            for axis in ['X', 'Y', 'Z']:\n",
    "                col = 'MatchedHit_D{}[{}]'.format(axis, station)\n",
    "                col_prev = 'MatchedHit_D{}[{}]'.format(axis, station-1)\n",
    "                ind_null = dataDF[col].isnull()\n",
    "                if ind_null.sum() == 0: \n",
    "                    continue\n",
    "                dataDF.loc[ind_null, col] = dataDF.loc[ind_null, col_prev] * MatchedHit_R[axis]\n",
    "            if not essential:\n",
    "                for axis in ['x', 'y']:\n",
    "                    closesthit_R[axis] = \\\n",
    "                    dataDF['closest_d{}_per_station[{}]'.format(axis,station)].dropna().median() / dataDF['closest_d{}_per_station[{}]'.format(axis,station-1)].dropna().median()\n",
    "                for axis in ['x', 'y']:\n",
    "                    col = 'closest_d{}_per_station[{}]'.format(axis,station)\n",
    "                    col_prev = 'closest_d{}_per_station[{}]'.format(axis,station-1)\n",
    "                    ind_null = dataDF[col].isnull()\n",
    "                    if ind_null.sum() == 0: \n",
    "                        continue\n",
    "                    dataDF.loc[ind_null, col] = dataDF.loc[ind_null, col_prev] * closesthit_R[axis]\n",
    "    \n",
    "    if substitution_f == True:\n",
    "        for mcol in tqdm(imputation_dict.keys(), desc=\"substitution imputation\"):\n",
    "            if mcol not in dataDF.columns:\n",
    "                continue\n",
    "            ind_null = dataDF[mcol].isnull()\n",
    "            if ind_null.sum() == 0: \n",
    "                continue\n",
    "            dataDF.loc[ind_null, mcol] = dataDF.loc[ind_null, imputation_dict[mcol]]\n",
    "    \n",
    "    if mean_f == True:\n",
    "        for col in tqdm(['MatchedHit_Z[2]', 'MatchedHit_Z[3]', 'closest_z_per_station[2]', 'closest_z_per_station[3]',\n",
    "                         'closest_x_per_station[2]', 'closest_x_per_station[3]', 'closest_y_per_station[2]', 'closest_y_per_station[3]', \n",
    "                         'average_x_per_station[2]',  'average_x_per_station[3]',  'average_y_per_station[2]', 'average_y_per_station[3]'], \n",
    "                        desc=\"Mean value imputation\"):\n",
    "            if essential and col in ['average_x_per_station[2]',  'average_x_per_station[3]',  'average_y_per_station[2]', 'average_y_per_station[3]']:\n",
    "                continue\n",
    "            if col not in dataDF.columns:\n",
    "                continue\n",
    "            ind_null = dataDF[col].isnull()\n",
    "            if ind_null.sum() == 0: \n",
    "                continue\n",
    "            dataDF.loc[ind_null, col] = dataDF[col].mean()\n",
    "    \n",
    "    if angle_f == True:\n",
    "        for col in tqdm(['MAngle[0]', 'MAngle[1]', 'MAngle', 'MAngle_v2[0]', 'MAngle_v2[1]', 'MAngle_v2[2]'], \n",
    "                        desc=\"angle imputation\"):\n",
    "            if not col in dataDF.columns:\n",
    "                continue\n",
    "            ind_null = dataDF[col].isnull()\n",
    "            if ind_null.sum() == 0: \n",
    "                continue\n",
    "            vec_col = []\n",
    "            vec_col2 = []\n",
    "            if col == 'MAngle[0]':\n",
    "                vec_col = ['MatchedHit_X[0]','MatchedHit_Y[0]','MatchedHit_Z[0]', \n",
    "                           'MatchedHit_X[1]', 'MatchedHit_Y[1]', 'MatchedHit_Z[1]']\n",
    "                vec_col2 =  ['MatchedHit_X[1]','MatchedHit_Y[1]','MatchedHit_Z[1]', \n",
    "                           'MatchedHit_X[2]', 'MatchedHit_Y[2]', 'MatchedHit_Z[2]']\n",
    "            elif col == 'MAngle[1]':\n",
    "                vec_col =  ['MatchedHit_X[1]','MatchedHit_Y[1]','MatchedHit_Z[1]', \n",
    "                           'MatchedHit_X[2]', 'MatchedHit_Y[2]', 'MatchedHit_Z[2]']\n",
    "                vec_col2 = ['MatchedHit_X[2]','MatchedHit_Y[2]','MatchedHit_Z[2]', \n",
    "                           'MatchedHit_X[3]', 'MatchedHit_Y[3]', 'MatchedHit_Z[3]']\n",
    "            elif col == 'MAngle':\n",
    "                vec_col = ['MatchedHit_X[0]','MatchedHit_Y[0]','MatchedHit_Z[0]', \n",
    "                           'MatchedHit_X[1]', 'MatchedHit_Y[1]', 'MatchedHit_Z[1]']\n",
    "                vec_col2 = [0, 0, 0, 'MatchedHit_X[0]', 'MatchedHit_Y[0]', 'MatchedHit_Z[0]']\n",
    "            elif col == 'MAngle_v2[0]':\n",
    "                vec_col = ['MatchedHit_X[0]','MatchedHit_Y[0]','MatchedHit_Z[0]', \n",
    "                           'MatchedHit_X[1]', 'MatchedHit_Y[1]', 'MatchedHit_Z[1]']\n",
    "                vec_col2 = [0, 0, 0, 'Lextra_X[0]', 'Lextra_Y[0]', 'MatchedHit_Z[0]']\n",
    "            elif col == 'MAngle_v2[1]':\n",
    "                vec_col =  ['MatchedHit_X[1]','MatchedHit_Y[1]','MatchedHit_Z[1]', \n",
    "                           'MatchedHit_X[2]', 'MatchedHit_Y[2]', 'MatchedHit_Z[2]']\n",
    "                vec_col2 = [0, 0, 0, 'Lextra_X[1]', 'Lextra_Y[1]', 'MatchedHit_Z[1]']\n",
    "            elif col == 'MAngle_v2[2]':\n",
    "                vec_col =  ['MatchedHit_X[2]','MatchedHit_Y[2]','MatchedHit_Z[2]', \n",
    "                           'MatchedHit_X[3]', 'MatchedHit_Y[3]', 'MatchedHit_Z[3]']\n",
    "                vec_col2 = [0, 0, 0, 'Lextra_X[2]', 'Lextra_Y[2]', 'MatchedHit_Z[2]']\n",
    "\n",
    "            delta = pd.DataFrame(index = dataDF.index[ind_null])\n",
    "            for i, axis in enumerate(['X', 'Y', 'Z']):\n",
    "                delta.loc[ind_null, axis+'1'] = dataDF.loc[ind_null, vec_col[3+i]] - dataDF.loc[ind_null, vec_col[i]]\n",
    "                if col in ['MAngle[0]','MAngle[1]']:\n",
    "                    delta.loc[ind_null, axis+'2'] = dataDF.loc[ind_null, vec_col2[3+i]] - dataDF.loc[ind_null, vec_col2[i]]\n",
    "                else:\n",
    "                    delta.loc[ind_null, axis+'2'] = dataDF.loc[ind_null, vec_col2[3+i]] - vec_col2[i]\n",
    "            delta = delta[['X1','Y1','Z1','X2','Y2','Z2']]\n",
    "            dataDF.loc[ind_null, col] = delta.progress_apply(lambda x: angle(x.values), axis=1)\n",
    "            del delta\n",
    "    \n",
    "    if average_xy_f == True:\n",
    "        for station in tqdm(range(4), desc='average_xy'):\n",
    "            col = 'closest_xy_per_station[{}]'.format(station)\n",
    "            if not col in dataDF.columns:\n",
    "                continue\n",
    "            ind_null = dataDF[col].isnull()\n",
    "            if ind_null.sum() == 0:\n",
    "                continue\n",
    "            dataDF.loc[ind_null, col] = dataDF.loc[ind_null, 'closest_x_per_station[{}]'.format(station)] + dataDF.loc[ind_null, 'closest_y_per_station[{}]'.format(station)]\n",
    "\n",
    "    gc.collect()\n",
    "    return dataDF\n",
    "\n",
    "def angle(arr):\n",
    "    x = arr[0:3]\n",
    "    y = arr[3:]\n",
    "    dot_xy = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    cos = dot_xy / (norm_x*norm_y)\n",
    "    cos = np.clip(cos, -1, 1)\n",
    "    rad = np.arccos(cos)\n",
    "    theta = rad * 180 / np.pi\n",
    "    return theta\n",
    "\n",
    "def data_check(dataDF):\n",
    "    print(dataDF.shape)\n",
    "    null_col = []\n",
    "    for col in tqdm(dataDF.columns, desc='checking data...,'):\n",
    "        ind_null = dataDF[col].isnull()\n",
    "        if ind_null.sum() == 0:\n",
    "            continue\n",
    "        print('{}: {} null items found'.format(col, ind_null.sum()))\n",
    "        null_col.append(col)\n",
    "        display(dataDF.loc[ind_null, col].head(5))\n",
    "    return null_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import preprocessed data from track 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = pd.read_hdf('01_rawdata/trn_154col.hdf') # this is the preprocess train data from track 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trn_data[utils.TRAIN_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = trn_data[utils.COL_ESSENTIAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = missing_value_imputation(x_train, essential=True, \n",
    "                                   ratio_f=False, mean_f=False, substitution_f=False, angle_f=True, average_xy_f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = data_check(x_train) # some features are left nan deliberately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trn_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something to do with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_flipper(data, threshold=4000, multiplier=2.0):\n",
    "    ind_negative = (data['weight'] < 0)\n",
    "    \n",
    "    ind_label0_negative = (data[\"weight\"] > -threshold) & (data['weight'] < 0) & (data[\"label\"] == 0)\n",
    "    data.loc[ind_label0_negative, 'weight'] = data['weight'].map(lambda x: multiplier * x)\n",
    "    \n",
    "    data.loc[ind_negative, 'weight'] = data['weight'].map(lambda x: -1.0 * x)\n",
    "    data.loc[ind_negative, 'label'] = data['label'].map(lambda x: 1-x)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_raw = y_train['weight'].copy()\n",
    "y_raw = y_train['label'].copy()\n",
    "flipped_y = weight_flipper(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cv_trn, x_cv_test, y_cv_trn, y_cv_test, w_cv_trn, w_cv_test = \\\n",
    "    train_test_split(x_train, flipped_y['label'], flipped_y['weight'], test_size=0.2, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cv_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Pool(\n",
    "    data = x_cv_trn.values,\n",
    "    label = y_cv_trn.values,\n",
    "    weight = w_cv_trn.values)\n",
    "eval_data = Pool(\n",
    "    data = x_cv_test.values,\n",
    "    label = y_cv_test.values,\n",
    "    weight = w_cv_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {'iterations':10000, 'eval_metric':'RMSE', 'one_hot_max_size':5,\n",
    "              'use_best_model':True, 'random_state':None, 'thread_count':7}\n",
    "fit_params = {'early_stopping_rounds':10, 'verbose':False, 'plot':True}\n",
    "\n",
    "cat = CatBoostRegressor(depth=7, random_strength=40, bagging_temperature=0.2, \n",
    "                              learning_rate=0.06, \n",
    "                              **cat_params)\n",
    "cat.fit(X=train_data, eval_set=eval_data, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'imp': cat.feature_importances_, 'col': x_cv_trn.columns})\n",
    "_ = importance.plot(kind='barh', x='col', y='imp', figsize=(20, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and model export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cat.predict(x_cv_test)\n",
    "scoring.rejection90(y_raw.loc[y_cv_test.index], pred, sample_weight=w_raw.loc[x_cv_test.index].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.save_model('cpp_track_2/model.cbm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
